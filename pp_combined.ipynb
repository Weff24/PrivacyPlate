{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFyGaaEwGrlXaV02ge4YY3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Weff24/PrivacyPlate/blob/main/pp_combined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Notebook Setups"
      ],
      "metadata": {
        "id": "n21KBB2wp8RP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Install Environment Requirements"
      ],
      "metadata": {
        "id": "wPHIzGs4qGAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install -U yolov5"
      ],
      "metadata": {
        "id": "CRe2X05iqFSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import yolov5\n",
        "\n",
        "pytesseract.pytesseract.tesseract_cmd = ( r'/usr/bin/tesseract' )"
      ],
      "metadata": {
        "id": "LuOQsrv1rX9b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Setup Methods"
      ],
      "metadata": {
        "id": "RIfOtxeaqBQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BRNcLsplpO6P"
      },
      "outputs": [],
      "source": [
        "### Extraction Method ###\n",
        "def extract_license_plate_text(image_path):\n",
        "    # Read the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding or other preprocessing techniques if needed\n",
        "    # Example: gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    # Use Tesseract OCR to extract text\n",
        "    text = pytesseract.image_to_string(gray, config='--psm 7 --oem 1')\n",
        "\n",
        "    return text\n",
        "\n",
        "### Loading Model For Yolo ###\n",
        "def load_model_bounding():\n",
        "  model = yolov5.load('keremberke/yolov5m-license-plate')\n",
        "\n",
        "  # set model parameters\n",
        "  model.conf = 0.5  # NMS confidence threshold\n",
        "  model.iou = 0.45  # NMS IoU threshold\n",
        "  model.agnostic = False  # NMS class-agnostic\n",
        "  model.multi_label = False  # NMS multiple labels per box\n",
        "  model.max_det = 1000  # maximum number of detections per image\n",
        "\n",
        "  return model\n",
        "\n",
        "### Show Bounding Boxes Using Yolo ###\n",
        "def bounding_box_show(image_path, model):\n",
        "  # perform inference\n",
        "  results = model(image_path, size=640)\n",
        "\n",
        "  # inference with test time augmentation\n",
        "  results = model(image_path, augment=True)\n",
        "\n",
        "  # parse results\n",
        "  predictions = results.pred[0]\n",
        "  boxes = predictions[:, :4] # x1, y1, x2, y2\n",
        "  scores = predictions[:, 4]\n",
        "  categories = predictions[:, 5]\n",
        "\n",
        "  # show detection bounding boxes on image\n",
        "  results.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Image Blurring"
      ],
      "metadata": {
        "id": "nkpd_VqZqwVn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3gvgRmdyqvY4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Pipeline Evaluation"
      ],
      "metadata": {
        "id": "QLolanHBqyUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bounding_box_model = load_model_bounding()\n",
        "\n",
        "while True:\n",
        "  # 1. Ask for user input of the image path\n",
        "  img_path = input(\"Please enter your desired image (q to quit)\")\n",
        "  if img_path == \"q\":\n",
        "    print(\"Exiting...\")\n",
        "    break\n",
        "\n",
        "  extracted_text = extract_license_plate_text(img_path)\n",
        "\n",
        "  # 1. Extracted text first\n",
        "  if len(extracted_text) != 0:\n",
        "    print(f\"Extracted text from - {img_path}: {extracted_text}\")\n",
        "    continue\n",
        "\n",
        "  # 2. Run YOLO model to show bounding box if the extracted text is empty\n",
        "  bounding_box_show(img_path, bounding_box_model)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQm21UZFq2JZ",
        "outputId": "32f7e535-9e87-4905-f9a8-2d182cd4e4ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your desired image (q to quit)test.png\n",
            "Extracted text from - test.png: EPGeMN112]\n",
            "\f\n",
            "Please enter your desired image (q to quit)q\n",
            "Exiting...\n"
          ]
        }
      ]
    }
  ]
}